{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/koconno8/CS436FinalProject/blob/main/FinalProject436.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YgewrWieVwje"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "import time\n",
        "import random\n",
        "import getopt\n",
        "import sys\n",
        "import os\n",
        "import logging"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = conv3x3(in_planes, planes, stride)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = F.relu(self.bn2(self.conv2(out)))\n",
        "        out += self.shortcut(x) if self.shortcut else x\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = F.relu(self.bn2(self.conv2(out)))\n",
        "        out = self.bn3(self.conv3(out))\n",
        "        out += self.shortcut(x) if self.shortcut else x\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = 64\n",
        "\n",
        "        self.conv1 = conv3x3(3,64)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "def ResNet18():\n",
        "    return ResNet(BasicBlock, [2,2,2,2])\n",
        "\n",
        "def ResNet34():\n",
        "    return ResNet(BasicBlock, [3,4,6,3])\n",
        "\n",
        "def ResNet50():\n",
        "    return ResNet(Bottleneck, [3,4,6,3])\n",
        "\n",
        "def ResNet101():\n",
        "    return ResNet(Bottleneck, [3,4,23,3])\n",
        "\n",
        "def ResNet152():\n",
        "    return ResNet(Bottleneck, [3,8,36,3])\n",
        "\n",
        "def test_resnet():\n",
        "    net = ResNet50()\n",
        "    y = net(Variable(torch.randn(1,3,32,32)))\n",
        "    print(y.size())"
      ],
      "metadata": {
        "id": "cZSQOyvYWB0O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.isdir('./results'):\n",
        "    os.mkdir('./results')\n",
        "if not os.path.isdir('./log'):\n",
        "    os.mkdir('./log')\n",
        "if not os.path.isdir('./models'):\n",
        "    os.mkdir('./models')\n",
        "if not os.path.isdir('./data'):\n",
        "    os.mkdir('./data')\n",
        "if not os.path.isdir('./runs'):\n",
        "    os.mkdir('./runs')\n",
        "\n",
        "#READ ARGUMENTS\n",
        "opts = sys.argv[1::2]\n",
        "args = sys.argv[2::2]\n",
        "\n",
        "#Defaults\n",
        "l_ce = 1.0\n",
        "l2_reg = 10.0\n",
        "mul = 4.0\n",
        "TRAIN_BATCH_SIZE = 64\n",
        "Feps = 8.0\n",
        "B_val = 4.0\n",
        "MAX_EPOCHS = 100\n",
        "lr_factor = 10.0\n",
        "\n",
        "for i in range(len(opts)):\n",
        "    opt = opts[i]\n",
        "    arg = args[i]\n",
        "    #Experiment name\n",
        "    if opt=='-EXP_NAME':\n",
        "        EXP_NAME = str(arg)\n",
        "        LOG_FILE_NAME = 'log/'+str(arg)+'.txt'\n",
        "        print('EXP_NAME:',EXP_NAME)\n",
        "    if opt=='-MAX_EPOCHS':\n",
        "        MAX_EPOCHS = int(arg)\n",
        "        print('MAX_EPOCHS:',MAX_EPOCHS)\n",
        "    if opt=='-l_ce':\n",
        "        l_ce = float(arg)\n",
        "        print('l_ce:',l_ce)\n",
        "    if opt=='-B_val':\n",
        "        B_val = float(arg)\n",
        "        print('Initial Noise Magnitude:',B_val)\n",
        "    if opt=='-l2_reg':\n",
        "        l2_reg = float(arg)\n",
        "        print('l2_reg:',l2_reg)\n",
        "    if opt=='-b_size':\n",
        "        TRAIN_BATCH_SIZE = int(arg)\n",
        "        print('Training Batch Size:',TRAIN_BATCH_SIZE)\n",
        "    if opt=='-Feps':\n",
        "        Feps = float(arg)\n",
        "        print('RFGSM Epsilon:',Feps)\n",
        "    if opt=='-lr_factor':\n",
        "        lr_factor = float(arg)\n",
        "        print('lr_factor:',lr_factor)\n",
        "    if opt=='-mul':\n",
        "        mul = float(arg)\n",
        "        print('Step Mult. factor:',mul)\n",
        "\n",
        "writer = SummaryWriter(log_dir=\"runs/\"+EXP_NAME)\n",
        "\n",
        "###################################### Function Definitions #######################################\n",
        "\n",
        "def Guided_Attack(model, loss, image, target, eps=8/255, bounds=[0,1], steps=1, P_out=[], l2_reg=10, alt=1):\n",
        "    tar = Variable(target.cuda())\n",
        "    img = image.cuda()\n",
        "    eps = eps/steps\n",
        "    for step in range(steps):\n",
        "        img = Variable(img,requires_grad=True)\n",
        "        if img.grad is not None:\n",
        "            img.grad.zero_()\n",
        "        out = model(img)\n",
        "        R_out = nn.Softmax(dim=1)(out)\n",
        "        cost = loss(out,tar) + alt*l2_reg*(((P_out - R_out)**2.0).sum(1)).mean(0)\n",
        "        cost.backward()\n",
        "        per = eps * torch.sign(img.grad.data)\n",
        "        adv = img.data + per.cuda()\n",
        "        img = torch.clamp(adv,bounds[0],bounds[1])\n",
        "    return img\n",
        "\n",
        "def execfile(filepath):\n",
        "    with open(filepath, 'rb') as file:\n",
        "        exec(compile(file.read(), filepath, 'exec'))\n",
        "        globals().update(locals())\n",
        "\n",
        "#######################################Cudnn##############################################\n",
        "torch.backends.cudnn.enabled = True\n",
        "torch.backends.cudnn.benchmark=True\n",
        "print('Cudnn status:',torch.backends.cudnn.enabled)\n",
        "#######################################Set tensor to CUDA#########################################\n",
        "torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
        "#######################################Parameters##################################################\n",
        "TRAIN_BATCH_SIZE = TRAIN_BATCH_SIZE\n",
        "VAL_BATCH_SIZE   = 128\n",
        "TEST_BATCH_SIZE   = 128\n",
        "BASE_LR          = 1e-1\n",
        "MAX_ITER         = (MAX_EPOCHS*50000)/TRAIN_BATCH_SIZE\n",
        "MODEL_PREFIX     = 'models/' + EXP_NAME + '_'\n",
        "\n",
        "####################################### load network ################################################\n",
        "execfile('ResNet.py')\n",
        "model = ResNet18()\n",
        "model.cuda()\n",
        "model.train()\n",
        "\n",
        "###################################### load data ####################################################\n",
        "transform_train = transforms.Compose([\n",
        "        transforms.RandomCrop(size=32,padding=4),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "        transforms.ToTensor(),])\n",
        "\n",
        "train_set  = torchvision.datasets.CIFAR10(root='./data', train=True , download=True, transform=transform_train)\n",
        "val_set    = torchvision.datasets.CIFAR10(root='./data', train=True , download=True, transform=transform_test)\n",
        "test_set   = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "\n",
        "# Creating Train-Val split from original Training set\n",
        "train_size = 49000\n",
        "valid_size = 1000\n",
        "test_size  = 10000\n",
        "\n",
        "train_indices = list(range(50000))\n",
        "val_indices = []\n",
        "count = np.zeros(10)\n",
        "for index in range(len(train_set)):\n",
        "    _, target = train_set[index]\n",
        "    if(np.all(count==100)):\n",
        "        break\n",
        "    if(count[target]<100):\n",
        "        count[target] += 1\n",
        "        val_indices.append(index)\n",
        "        train_indices.remove(index)\n",
        "\n",
        "print(\"Size of train set:\",len(train_indices))\n",
        "print(\"Size of val set:\",len(val_indices))\n",
        "\n",
        "#get data loader for train, val and test\n",
        "train_loader = torch.utils.data.DataLoader(train_set,batch_size=TRAIN_BATCH_SIZE ,sampler=SubsetRandomSampler(train_indices))\n",
        "val_loader   = torch.utils.data.DataLoader(val_set,sampler = SubsetRandomSampler(val_indices),batch_size=VAL_BATCH_SIZE)\n",
        "test_loader   = torch.utils.data.DataLoader(test_set,batch_size=TEST_BATCH_SIZE)\n",
        "print('CIFAR10 dataloader: Done')\n",
        "\n",
        "###################################################################################################\n",
        "epochs    = MAX_EPOCHS\n",
        "iteration = 0\n",
        "loss      = nn.CrossEntropyLoss()\n",
        "LR = BASE_LR\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=LR,momentum=0.9,weight_decay=5e-4)\n",
        "optimizer.zero_grad()\n",
        "\n",
        "##################################################################################################\n",
        "for epoch in range(epochs):\n",
        "    start = time.time()\n",
        "    iter_loss =0\n",
        "    counter =0\n",
        "    total_ce_loss = torch.tensor([0.0])\n",
        "    total_reg_loss = torch.tensor([0.0])\n",
        "\n",
        "    for data, target in train_loader:\n",
        "        data   = Variable(data).cuda()\n",
        "        target = Variable(target).cuda()\n",
        "\n",
        "        out  = model(data)\n",
        "        P_out = nn.Softmax(dim=1)(out)\n",
        "\n",
        "        adv_data = data + ((B_val/255.0)*torch.sign(torch.tensor([0.5]) - torch.rand_like(data)).cuda())\n",
        "        adv_data = torch.clamp(adv_data,0.0,1.0)\n",
        "\n",
        "        model.eval()\n",
        "        adv_data = Guided_Attack(model,loss,adv_data,target,eps=Feps/255.0,steps=1,P_out=P_out,l2_reg=l2_reg,alt=(counter%2))\n",
        "\n",
        "        delta = adv_data - data\n",
        "        delta = torch.clamp(delta,-8.0/255.0,8.0/255)\n",
        "        adv_data = data+delta\n",
        "        adv_data = torch.clamp(adv_data,0.0,1.0)\n",
        "\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        adv_out  = model(adv_data)\n",
        "        out  = model(data)\n",
        "\n",
        "        Q_out = nn.Softmax(dim=1)(adv_out)\n",
        "        P_out = nn.Softmax(dim=1)(out)\n",
        "\n",
        "        '''LOSS COMPUTATION'''\n",
        "        closs = loss(out,target)\n",
        "        reg_loss = ((P_out - Q_out)**2.0).sum(1).mean(0)\n",
        "        cost = l_ce*closs + l2_reg*reg_loss\n",
        "        cost.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_ce_loss += closs.data\n",
        "        total_reg_loss += l2_reg*reg_loss.data\n",
        "\n",
        "        if iteration%100==0:\n",
        "            msg = 'iter,'+str(iteration)+',clean loss,'+str(closs.data.cpu().numpy()) \\\n",
        "            +',reg loss,'+str(reg_loss.data.cpu().numpy()) \\\n",
        "            +',total loss,'+str(cost.data.cpu().numpy()) \\\n",
        "            +'\\n'\n",
        "            log_file = open(LOG_FILE_NAME,'a+')\n",
        "            log_file.write(msg)\n",
        "            log_file.close()\n",
        "            model.train()\n",
        "\n",
        "        iteration = iteration + 1\n",
        "        counter = counter + 1\n",
        "        sys.stdout.write('\\r')\n",
        "        sys.stdout.write('| Epoch [%3d/%3d] Iter[%3d/%3d] : Loss:%f \\t\\t'\n",
        "                %(epoch, MAX_EPOCHS, counter,\n",
        "                    (train_size/TRAIN_BATCH_SIZE),cost.data.cpu().numpy()))\n",
        "    end = time.time()\n",
        "    print('Epoch:',epoch,' Time taken:',(end-start))\n",
        "\n",
        "    model_name = MODEL_PREFIX+str(epoch)+'.pkl'\n",
        "    torch.save(model.state_dict(),model_name)\n",
        "\n",
        "    writer.add_scalar(\"Loss/Train_CE_loss\", total_ce_loss, epoch)\n",
        "    writer.add_scalar(\"Loss/Train_Reg_loss\", total_reg_loss, epoch)\n",
        "\n",
        "    if epoch in [70,85]:\n",
        "        LR /= lr_factor\n",
        "        for param_group in optimizer.param_groups:\n",
        "            param_group['lr'] = LR\n",
        "    if epoch == 85:\n",
        "        l2_reg = l2_reg*mul\n",
        "\n",
        "#######################################################################################################################\n",
        "model.eval()\n",
        "\n",
        "def FGSM_Attack_step(model,loss,image,target,eps=8/255,bounds=[0,1],steps=30):\n",
        "    tar = Variable(target.cuda())\n",
        "    img = image.cuda()\n",
        "    eps = eps/steps\n",
        "    for step in range(steps):\n",
        "        img = Variable(img,requires_grad=True)\n",
        "        if img.grad is not None:\n",
        "            img.grad.zero_()\n",
        "        out  = model(img)\n",
        "        cost = loss(out,tar)\n",
        "        cost.backward()\n",
        "        per = eps * torch.sign(img.grad.data)\n",
        "        adv = img.data + per.cuda()\n",
        "        img = torch.clamp(adv,bounds[0],bounds[1])\n",
        "    return img\n",
        "\n",
        "def MSPGD(model,loss,data,target,eps=8/255,eps_iter=2/255,bounds=[],steps=[7,20,50,100,500]):\n",
        "    \"\"\"\n",
        "    model\n",
        "    loss : loss used for training\n",
        "    data : input to network\n",
        "    target : ground truth label corresponding to data\n",
        "    eps : perturbation srength added to image\n",
        "    eps_iter\n",
        "    \"\"\"\n",
        "    if model.training:\n",
        "        assert 'Model is in  training mode'\n",
        "    tar = Variable(target.cuda())\n",
        "    data = data.cuda()\n",
        "    B,C,H,W = data.size()\n",
        "    noise  = torch.FloatTensor(np.random.uniform(-eps,eps,(B,C,H,W))).cuda()\n",
        "    noise  = torch.clamp(noise,-eps,eps)\n",
        "    img_arr = []\n",
        "    for step in range(steps[-1]):\n",
        "        img = data + noise\n",
        "        img = Variable(img,requires_grad=True)\n",
        "        if img.grad is not None:\n",
        "            img.grad.zero_()\n",
        "        out  = model(img)\n",
        "        cost = loss(out,tar)\n",
        "        cost.backward()\n",
        "        per =  torch.sign(img.grad.data)\n",
        "        per[:,0,:,:] = (eps_iter * (bounds[0,1] - bounds[0,0])) * per[:,0,:,:]\n",
        "        if(per.size(1)>1):\n",
        "            per[:,1,:,:] = (eps_iter * (bounds[1,1] - bounds[1,0])) * per[:,1,:,:]\n",
        "            per[:,2,:,:] = (eps_iter * (bounds[2,1] - bounds[2,0])) * per[:,2,:,:]\n",
        "        adv = img.data + per.cuda()\n",
        "        img.requires_grad =False\n",
        "        img[:,0,:,:] = torch.clamp(adv[:,0,:,:],bounds[0,0],bounds[0,1])\n",
        "        if(per.size(1)>1):\n",
        "            img[:,1,:,:] = torch.clamp(adv[:,1,:,:],bounds[1,0],bounds[1,1])\n",
        "            img[:,2,:,:] = torch.clamp(adv[:,2,:,:],bounds[2,0],bounds[2,1])\n",
        "        img = img.data\n",
        "        noise = img - data\n",
        "        noise  = torch.clamp(noise,-eps,eps)\n",
        "        for j in range(len(steps)):\n",
        "            if step == steps[j]-1:\n",
        "                img_tmp = data + noise\n",
        "                img_arr.append(img_tmp)\n",
        "                break\n",
        "    return img_arr\n",
        "\n",
        "def max_margin_loss(x,y):\n",
        "    B = y.size(0)\n",
        "    corr = x[range(B),y]\n",
        "    x_new = x - 1000*torch.eye(10)[y].cuda()\n",
        "    tar = x[range(B),x_new.argmax(dim=1)]\n",
        "    loss = tar - corr\n",
        "    loss = torch.mean(loss)\n",
        "    return loss\n",
        "\n",
        "def GAMA_PGD(model, data, target, eps, eps_iter, bounds, steps, w_reg, lin, SCHED, drop):\n",
        "    #Raise error if in training mode\n",
        "    if model.training:\n",
        "        assert 'Model is in  training mode'\n",
        "    tar = Variable(target.cuda())\n",
        "    data = data.cuda()\n",
        "    B,C,H,W = data.size()\n",
        "    noise  = torch.FloatTensor(np.random.uniform(-eps,eps,(B,C,H,W))).cuda()\n",
        "    noise  = eps*torch.sign(noise)\n",
        "    img_arr = []\n",
        "    W_REG = w_reg\n",
        "    orig_img = data+noise\n",
        "    orig_img = Variable(orig_img,requires_grad=True)\n",
        "    for step in range(steps[-1]):\n",
        "        # convert data and corresponding into cuda variable\n",
        "        img = data + noise\n",
        "        img = Variable(img,requires_grad=True)\n",
        "\n",
        "        if step in SCHED:\n",
        "            eps_iter /= drop\n",
        "\n",
        "        # make gradient of img to zeros using .zero_()\n",
        "        if img.grad is not None:\n",
        "            img.grad.zero_()\n",
        "\n",
        "        # forward pass\n",
        "        orig_out = model(orig_img)\n",
        "        P_out = nn.Softmax(dim=1)(orig_out)\n",
        "\n",
        "        out  = model(img)\n",
        "        Q_out = nn.Softmax(dim=1)(out)\n",
        "        #compute loss using true label\n",
        "        if step <= lin:\n",
        "            cost =  W_REG*((P_out - Q_out)**2.0).sum(1).mean(0) + max_margin_loss(Q_out,tar)\n",
        "            W_REG -= w_reg/lin\n",
        "        else:\n",
        "            cost = max_margin_loss(Q_out,tar)\n",
        "        #backward pass\n",
        "        cost.backward()\n",
        "        #get gradient of loss wrt data\n",
        "        per =  torch.sign(img.grad.data)\n",
        "        #convert eps 0-1 range to per channel range\n",
        "        per[:,0,:,:] = (eps_iter * (bounds[0,1] - bounds[0,0])) * per[:,0,:,:]\n",
        "        if(per.size(1)>1):\n",
        "            per[:,1,:,:] = (eps_iter * (bounds[1,1] - bounds[1,0])) * per[:,1,:,:]\n",
        "            per[:,2,:,:] = (eps_iter * (bounds[2,1] - bounds[2,0])) * per[:,2,:,:]\n",
        "        #  ascent\n",
        "        adv = img.data + per.cuda()\n",
        "        #clip per channel data out of the range\n",
        "        img.requires_grad =False\n",
        "        img[:,0,:,:] = torch.clamp(adv[:,0,:,:],bounds[0,0],bounds[0,1])\n",
        "        if(per.size(1)>1):\n",
        "            img[:,1,:,:] = torch.clamp(adv[:,1,:,:],bounds[1,0],bounds[1,1])\n",
        "            img[:,2,:,:] = torch.clamp(adv[:,2,:,:],bounds[2,0],bounds[2,1])\n",
        "        img = img.data\n",
        "        noise = img - data\n",
        "        noise  = torch.clamp(noise,-eps,eps)\n",
        "\n",
        "        for j in range(len(steps)):\n",
        "            if step == steps[j]-1:\n",
        "                img_tmp = data + noise\n",
        "                img_arr.append(img_tmp)\n",
        "                break\n",
        "    return img_arr"
      ],
      "metadata": {
        "id": "Jtk-OriZW5ja"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}